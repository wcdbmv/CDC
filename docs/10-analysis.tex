%% Методические указания к выполнению, оформлению и защите выпускной квалификационной работы бакалавра
%% 2.4 Аналитический раздел
%%
%% В данном разделе расчётно-пояснительной записки проводится анализ предметной области и выделяется основной объект исследования.
%% Если формализовать предметную область с помощью математической модели не удаётся и при этом она сложна для понимания, то для отображения происходящих в ней процессов необходимо использовать методологию IDEF0, а для описания сущностей предметной области и взаимосвязей между ними — ER-модель.
%%
%% Затем выполняется обзор существующих методов и алгоритмов решения идентифицированной проблемы предметной области (опять же с обязательными ссылками на научные источники: монографии, статьи и др.) и их программных реализаций (при наличии), анализируются достоинства и недостатки каждого из них.
%% Выполненный обзор должен позволить объективно оценить актуальное состояние изучаемой проблемы.
%% Результаты проведённого анализа по возможности классифицируются и оформляются в табличной форме.
%%
%% На основе выполненного анализа обосновывается необходимость разработки нового или адаптации существующего метода или алгоритма.
%%
%% Если же целью анализа являлся отбор (на основе чётко сформулированных критериев) тех методов и алгоритмов, которые наиболее эффективно решают поставленную задачу, то форма представления результата должна подтвердить обоснованность сделанного выбора, в том числе — полноту и корректность предложенных автором критериев отбора.
%%
%% Одним из основных выводов аналитического раздела должно стать формализованное описание проблемы предметной области, на решение которой будет направлен данный проект, включающее в себя:
%% — описание входных и выходных данных;
%% — указание ограничений, в рамках которых будет разработан новый, адаптирован существующий или просто реализован метод или алгоритм;
%% — описание критериев сравнения нескольких реализаций метода или алгоритма;
%% — описание способов тестирования разработанного, адаптированного или реализованного метода или алгоритма;
%% — описание функциональных требований к разрабатываемому программному обеспечению,
%% при этом в зависимости от направления работы отдельные пункты могут отсутствовать.
%%
%% Если в результате работы будет создано программное обеспечение, реализующее большое количество типичных способов взаимодействия с пользователем, необходимо каждый из этих способов описать с помощью диаграммы прецедентов [4, 5].
%%
%% Рекомендуемый объём аналитического раздела 25—30 страниц.


\chapter{Аналитический раздел}

В данном разделе приводится краткий обзор предметной области.
Рассмотрены основные этапы компиляции, а также проанализированы методы их реализации.

\section{Этапы компиляции}

Компиляция состоит из следующих основных этапов [1]:
\begin{itemize}
	\item лексический анализ;
	\item синтаксический анализ;
	\item семантический анализ;
	\item генерация кода.
\end{itemize}

\subsection{Лексический анализ}

Задачей лексического анализа является аналитический разбор входной цепочки символов, составляющих текст компилируемой программы, с целью получения на выходе последовательности токенов.
Также данный процесс называют «токенизацией».

Лексический анализатор функционирует в соответствии с некоторыми правилами построения допустимых входных последовательностей.
Данные правила могут быть определены, например, в виде детерминированного конечного автомата, регулярного выражения или праволинейной грамматики.
С практической точки зрения выяснено, что наиболее удобным способом является формализация работы лексического анализатора с помощью грамматики.

Лексический анализ может быть представлен и как самостоятельная фаза трансляции, и как составная часть фазы синтаксического анализа.
В первом случае лексический анализатор реализуется в виде отдельного модуля, который принимает последовательность символов, составляющих текст компилируемой программы, и выдаёт список обнаруженных лексем.
Во втором случае лексический анализатор фактически является подпрограммой, вызываемой синтаксическим анализатором для получения очередной лексемы [2].

В процессе лексического анализа обнаруживаются лексические ошибки — простейшие ошибки компиляции, связанные с наличием в тексте программы недопустимых символов, некорректной записью идентификаторов, числовых констант.

На этапе лексического анализа обычно также выполняются такие действия, как удаление комментариев и обработка директив условной компиляции.

\subsection{Синтаксический анализ}

Синтаксический анализатор использует поток токенов, полученный на этапе лексического анализа для создания древовидного промежуточного представления, которое описывает грамматическую структуру потока токенов.
Типичным представлением является абстрактное синтаксическое дерево, в котором каждый внутренний узел представляет операцию, а дочерние узлы — аргументы этой операции [3].

Последующие фазы компиляции используют грамматическую структуру, которая помогает проанализировать исходную программу и сгенерировать целевую.

На этапе синтаксического анализа фиксируются синтаксические ошибки, то есть ошибки, связанные с нарушением принятой структуры программы.

\subsection{Семантический анализ}

Семантический анализатор используя, синтаксические дерево, проверяет исходную программу на семантическую согласованность с определением языка.
Он также собирает информацию о всех встреченных типах и сохраняет ее для последующего использования в процессе генерации промежуточного кода.

Таким образом, семантический анализатор предназначен для нахождения семантических ошибок и накопления данных о переменных, функциях и используемых типах, используемых при генерации кода.

\subsection{Генерация кода}

Генерация кода — это последний этап процесса компиляции.
Зачастую данный этап компиляции включает в себя и машинно-зависимую оптимизацию кода.
На этом этапе компилятор генерирует машинно-зависимый код.
Генератор кода должен иметь представление о среде выполнения целевой машины и её наборе команд.

На этом этапе компилятор выполняет несколько основных задач:
\begin{itemize}
	\item выбор инструкций — какую инструкцию использовать;
	\item создание расписания инструкций — в каком порядке должны быть упорядочены инструкции;
	\item распределение регистров — выделение переменных в регистры процессора;
	\item отладка данных — отладка кода с помощью отладочных данных.
\end{itemize}

Итоговый машинный код, сгенерированный генератором кода, может быть выполнен на целевой машине.
Именно так высокоуровневый исходный код, преобразуется в формат, который можно запустить на любой целевой машине.

\section{Методы реализации лексического и синтаксического анализаторов}

Реализовать лексический и синтаксический анализаторы можно двумя
способами:
\begin{itemize}
	\item используя стандартные алгоритмы анализа;
	\item с помощью инструментов генерации анализаторов.
\end{itemize}

\section{Алгоритмы лексического и синтаксического анализа}

Существует два основных подхода к проведению синтаксического анализа: нисходящий анализ и восходящий.

Нисходящий синтаксический анализ решает задачу построения дерева разбора в прямом порядке обхода (обход в глубину).
То есть реализует поиск левого порождения входной строки [1].
В общем виде нисходящий анализ представлен в анализе методом рекурсивного спуска, который может использовать откаты, т.е. производить повторный просмотр считанных символов.

Восходящий синтаксический анализ соответствует построению дерева разбора для входной строки, начиная с листьев (снизу) и идя по направлению к корню (вверх).
Общий вид восходящего синтаксического анализа известен как анализ типа «перенос/свертка» [1].
На каждом шаге свертки некоторая подстрока, соответствующая правой части продукции, замещается левым символом данной продукции.

\section{Генераторы анализаторов}

Среди наиболее используемых генераторов анализаторов выделяются: Lex и Yacc, Accent, ANTLR.

Генератор синтаксических анализаторов YACC (Yet Another Compilers' Compiler) — это программа, которая строит LALR-анализаторы.
На вход YACC получает описание грамматики в форме, близкой к форме Бэкуса-Наура и некоторую дополнительную информацию.
Выходом является программа на языке Си, реализующая восходящий разбор.
Как правило, Yacc применяется в сочетании с Lex — стандартным генератором лексических анализаторов.

Accent не полагается на определенные подклассы контекстно-свободных грамматик.
Язык спецификаций Accent аналогичен языку Yacc, но Accent использует символические имена для атрибутов вместо чисел.
Это позволяет записывать вашу грамматику в расширенной форме Бэкуса-Наура, в которой можно указывать повторения, варианты выбора и необязательные части, не вводя специальных правил для этих целей.
Accent также можно использовать в сочетании с Lex.

ANTLR (ANother Tool for Language Recognition) — мощный генератор синтаксического анализатора для чтения, обработки, исполнения или перевода структурированных текстовых или двоичных файлов.
Он широко используется для создания языков, инструментов и фреймворков.

Из грамматики ANTLR генерирует синтаксический анализатор, который может строить и обходить деревья синтаксического анализа.
На основе правил заданной в виде РБНФ грамматики ANTLR генерирует классы нисходящего рекурсивного синтаксического анализатора.
При этом обход дерева разбора можно выполнить с использованием паттернов посетитель или слушатель~[4].

Принимая во внимание эффективность и простоту использования ANTLR, для построения кода синтаксического анализатора было решено применить в работе данный генератор.

\section{LLVM}

LLVM [5] — проект программной инфраструктуры для создания компиляторов и сопутствующих им утилит.
Состоит из набора компиляторов из языков высокого уровня (так называемых «фронтендов»), системы оптимизации, интерпретации и компиляции в машинный код.

В основе инфраструктуры используется RISC-подобная платформонезависимая система кодирования машинных инструкций (байткод LLVM IR), которая представляет собой высокоуровневый ассемблер.

Написан на C++, обеспечивает оптимизации на этапах компиляции, компоновки и исполнения.
Изначально в проекте были реализованы компиляторы для языков Си и C++ при помощи фронтенда Clang, позже появились фронтенды для множества языков, в том числе: ActionScript, Ада, C\#, Common Lisp, Crystal, CUDA, D, Delphi, Dylan, Fortran, Graphical G Programming Language, Halide, Haskell, Java (байткод), JavaScript, Julia, Kotlin, Lua, Objective-C, OpenGL Shading Language, Ruby, Rust, Scala, Swift, Xojo.

LLVM может создавать машинный код для множества архитектур, в том числе ARM, x86, x86-64, PowerPC, MIPS, SPARC, RISC-V и других (включая GPU от Nvidia и AMD).

Некоторые проекты имеют собственные LLVM-компиляторы (например LLVM-версия GCC), другие используют инфраструктуру LLVM, как например Glasgow Haskell Compiler.

Разработка начата в 2000 году в Университете Иллинойса. К середине 2010-х годов LLVM получил широкое распространение в индустрии: использовался, в том числе, в компаниях Adobe, Apple и Google. В частности, на LLVM основана подсистема OpenGL в Mac OS X 10.5, а iPhone SDK использует препроцессор (фронтенд) GCC с бэкэндом на LLVM. Apple и Google являются одними из основных спонсоров проекта, а один из основных разработчиков — Крис Латтнер — 11 лет проработал в Apple (с 2017 года — в Tesla Motors, с 2020 года — в разработчике процессоров и микроконтроллеров на архитектуре RISC-V SiFive).

LLVM поддерживает следующие типы данных:
\begin{itemize}
	\item целые числа произвольной разрядности;
	\item числа с плавающей точкой;
	\item пустое значение void;
	\item массивы;
	\item структуры;
	\item вектора для упрощения SIMD-операций;
	\item функции.
\end{itemize}

Большинство инструкций в LLVM принимает два аргумента (операнда) и возвращает одно значение (трёхадресный код).

Значения определяются текстовым идентификатором.
Локальные значения обозначаются префиксом \%, а глобальные — @.

Тип операндов всегда указывается явно и однозначно определяет тип результата.
Операнды арифметических инструкций должны иметь одинаковый тип, но сами инструкции «перегружены» для любых числовых типов и векторов.

LLVM поддерживает полный набор арифметических операций, побитовых логических операций и операций сдвига, а также специальные инструкции для работы с векторами.

LLVM IR строго типизирован, поэтому существуют операции приведения типов, которые явно кодируются специальными инструкциями.
Набор из 9 инструкций покрывает все возможные приведения между различными числовыми типами: целыми и с плавающей точкой, со знаком и без, различной разрядности и пр.
Кроме этого, есть инструкции преобразования между целыми и указателями, а также универсальная инструкция для приведения типов bitcast (ответственность за корректность таких преобразований возлагается на программиста).

Помимо значений-регистров, в LLVM есть и работа с памятью.
Значения в памяти адресуются типизированными указателями.
Обратиться к памяти можно с помощью двух инструкций: load и store.

Инструкция alloca выделяет память на стеке.
Память, выделенная alloca, автоматически освобождается при выходе из функции при помощи инструкций ret или unwind.

Для вычисления адресов элементов массивов, структур и т. д. с правильной типизацией используется инструкция getelementptr.
getelementptr только вычисляет адрес, но не обращается к памяти.
Инструкция принимает произвольное количество индексов и может разыменовывать структуры любой вложенности.

Также существует инструкции extractvalue и insertvalue.
Они отличаются от getelementptr тем, что принимают не указатель на агрегатный тип данных (массив или структуру), а само значение такого типа.
extractvalue возвращает соответственное значение подэлемента, а insertvalue порождает новое значение агрегатного типа.


%\section{Выводы}
